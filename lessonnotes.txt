Kubernetes Lesson Notes

Part 1 Main Kubernetes Components:

* Pod - Contains Containers, which have your apps running inside them, (maybe DB too, in a seperate container). Usually one main application per Pod.
So one applicaiton, one db maybe, in one pod. Each pod gets it's OWN IP address, NOT THE CONTAINER. Each pod can communicate with each other through these 
virtual IPs. Pods can DIE very easily...that's okay. If the pod dies, a new one will get created in it's place...which will get assigned a new IP address.
Because pods live and die all the time, you need to connect DBs to them through a 'Service'.

* Service is a permanant IP address that can be attached to each pod. Even if the Pod dies, the Service and it's IP address will stay. 
It is also a Load Balancer which sends request to different avaliable Nodes/Pods.

*External Service - An external service exposes the app to external sources,(like the web, for example). You'db
want your URL to look like THIS, for production: https://my-app.com. An IP Address is good for testing tho

*Internal Service - A service exposed INTERNALLY to communicate within your app, (like for DBs which you shouldn't be exposing 
trhough the web).

* Ingress - For an app name that would be in contact with the External service, you would create an 'Ingress'. The request STARTS
at the Ingress, then gets transferred as need be to a service.

Setup/Configuration.

*Database URL is usually put into the build applicaiton. This would have to be rebuilt int docker and pushed to a hub or somewhere.

*Kubernetes has a tool called ConfigMap, which handles external configuration of your application. COntains config data like URL of database, for example.
You would just need to connect it to a pod. That way, you don't have to build a new image, just change the ConfigMap.
DON'T PUT CREDENTIALS INTO CONFIGMAP. PUT IT IN SECRET.

* Secret is like configmap but for secret credentials like passwords. IT's base64 encoded. Warning, it's not enabled by default!

* Volumes - attaches a physical hard drive storage to your pod,(ideally to store DB information). Could be local or remote.
Think of it as an external hard drive into the K8 cluster. K8 does NOT manage data persistance.

* Node - A server connected to services with a managed IP. These contain pods that run our application/DB.
Each node has multipe pods on them.

* Deployment - A Blueprint for 'MyApp' pods. (Actually, this is an abstraction ON TOP of the Pods).
These will be managed to have a set amount active/deployed at one time.
In practice, you don't work with Pods...you work with deployments. You can scale the amount of replicas up and down.
DB cannot be replicated in a deployment...because DB have a state. For that, you need a 'StatefulSet''

* StatefulSet - Used for applications like DBs, (MySQL, etc.). Used for persistant data and scaling, making 
sure the DB reads/writes are syncrhonized. These deployments are somewhat tedious. That's why
DB are reccommended to be hosted OUTSIDE of the Kubernets cluster.


Part 2 K8 Architechture

* 3 processes must be installed on every node.
Container runtime, (like docker). 

Kubelet, which is a kubernetes process that interfaces with the running containers AND the node.
Kubelet actually manages starting the pod with a container inside.

Kube Proxy forwards the requests from services to the pods. For instance, it will take a request from the app
on the SAME pod, and forward it to a DB on the SAME pod.

* Master Nodes - Manage all the Application Nodes beneath them. Must have 4 processes running:

API Server - Like a Cluster Gateway of any updates into the cluster or queries intot he cluster. Acts as a gatekeeper for 
authentication. You have to talk to the API server on the master node. It validates your request, then forwards it to other processes,
(for creating a pod or whatever, or querying the health of your cluster). Good cuz you only have 1 entrypoint.

Scheduler - Schedules new pods inside the worker nodes. It also knows WHERE to put the pods, in terms of resources.  Kubelet is the actually 
thing that starts it.

Controller Manager - Detects when nodes die,(state changes in genearl). Makes a request to the scheduler to do that.

etcd - A Key value store of a cluster state...the cluster brain. If things change in the cluster, it gets stored/logged. For example, scheduler and 
api server use the information stored in here to perform actions. Applicaiton data is NOT stored in here, just for the master node processes data to work.

Master nodes are usually duplicated to control all of this.

Example Cluster setup: 2 Master Nodes, 3 work nodes.
Master nodes need less resources, worker nodes need more.Nodes can scale horizationtally as needed.

Part 3 Minkube Setup and Kubectl - Local Setup

Production Setup is 2 Master Nodes, on their on Physical/Virtual Nodes. Also, 4 or so Worker Nodes, also on their own VMs or Phsycial servers.
For testing on local machine, there's MiniKube

* MiniKube -  On Node K8 setup, with a 'Master Process' and a 'Worker Process' running. Docker is pre-installed, so pods can be installed. It is used in a virtual box or hypervisor.
Used primarily for testing.

* Kubectl - Used for interacting with MiniKube clusters. Can run commands to work with services, creates pods, create nodes, etc. Interacts with the 
API server on master node. You can also do this with your own API that accesses the Master API Server, or through a UI.

MiniKube Setup: https://minikube.sigs.k8s.io/docs/start/
KubeCTL Setup: https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/

minikube start starts a new cluster
NOTE, you need a hypervisor to start all of this. If you want a specific hypervisor you installed,
(in the tutorial, she used hyperkit), you can type this command:
minikube start --vm-driver=hyperkit
For Docker: minikube start --driver=docker
Make Docker the Default Driver: minikube config set driver docker

* Note, you'll need to do this every time your host machine shuts down.

Some commands: 
kubectl get nodes = gets all your nodes.
minikube status = gets the status of your minikube
kubectl version = latest version of kubernetes installed



Part 4 Basic Kubectl Commands
kubectl get nodes
kubectl get pods
kubectl get services

To create pods:
kubectl create

* In practice, YOU aren't working with the pods, they are the smallest unit. YOU are working with deployments, 
the abstraction OVER pods.

Usage for creating things:
kubectl create deployment NAME --image=image [--dry-run] [options]

Example nginx deployment:
kubectl create deployment nginx-depl --image=nginx
										name o pod         the image
deployment has all the info for creating the pod

kubectl get replicaset gets the replicaset for the pods created...you reallly won't need to mess with these, just with deployments.

Layers of Abstraction:
 - Deployment manages a Replica-Set
	-Replicaset manage a pod
	- Pod is an abstraction of a container,(Docker-Image)

kubectl edit deployment NAME-OF-DEPLOYMENT
This generates a configuration file with default vides...she has a seperate video to break this down.

Do this to change the default text editor: https://www.youtube.com/watch?v=W3ZL5ehG8BA
example: export KUBE_EDITOR="code --wait"
verify: echo $KUBE_EDITOR

After editing this, a new pod will be created, old pod will die with new image.

To view logs inside the application pods:
kubectl logs POD_NAME

For her example, we created another deployment:
kubectl create deployment mongo-depl --image=mongo

You can also use 'describe' to get additional information about the pod:
kubectl describe pod POD_NAME

Another debugging tool is kubectl exec, which gets the actual terminal of the container:
Example: kubectl exec -it mongo-depl-5fd6b7d4b4-2zhct -- bin/bash

For deleting pods:
kubectl delete deployment 	NAME_O_DEPLOYMENT

All this command line crap can be hard to manage...that's why most people manage this through the Kubectl config files
Example: kubectl apply -f [file-name]          So this takes the configuration file to edit.
our example: kubectl apply -f nginx-deployment.yaml
creating that file: touch nginx-deployment.yaml
If you run that command again after making a change, it wont' create a new deployment, 
just update the already created deployment with that configuartion file


Part 5 Configuartion file for Deployments
Each Configuartion file has 3 parts: 

Extra: At the top, it's what type of 'item' you're creating. Example:
apiVersion: v1  === what version you're deploying in.
kind: Service === what you are configuring the file for
You can google this stuff for the different K8 components to see what their config yaml values are and what they do.

-- Part 1 - Metadata : Where the Meteadaata is, like the name.

-- Part 2 - Specification : Every configuation you want to apply for that component

The different Attributes are different based on what deployment you're configuring,(service, for example)

-- Part 3 - Status : This is automatically generated by  Kubernetes. It takes what's in the config yaml file, vesrus
what is ACTUALLY RUNNING IN KUBERNETES and notes something to fix if it dosen't match what the config file specified.
For example, if you have TWO replicas specified in a config file, and Kubernetes detects only 1 at runtime, Kubernetes will
update the state continuously

Kubernetes gets this status data from the etcd...THE BRAIN that gets updated from other master components.

To see if your yaml is valid, you can google 'yaml validator'
Good practice is to store these config files in your application code...'infrastructure as a code'...or you can have your own github for this configuration.

Lot to see in this section for configuration...might need to watch this part again. 

For services to forward incoming requests to application pods, the 'targetPort' must match the 'containerPort'
Ran these again to update our config files and start service specification.
kubectl apply -f nginx-deployment.yaml
kubectl apply -f nginx-service.yaml
kubectl describe service nginx-service

You can get more detailed pod information,(including IP Address) with this: kubectl get pod -o wide

Get status of cluster in etcd:
kubectl get deployment nginx-deployment -o yaml
Next, save that to a file
kubectl get deployment nginx-deployment -o yaml > nginx-deployment-result.yaml
You can take a look at this and it helps with debugging

You can delete the services as follows: 
kubectl delete -f nginx-deployment.yaml
kubectl delete -f nginx-service.yaml



Part 6 Complete Demo Project
What's it look like: Internal Service, an External Service, Secrets for DB Username and Password, A URL we can reach through enviornment variables too.
Request flow looks like: Request from browser ==> MongoExpress/External-Service ==> Mongo Express Pod ==> MongoDB Internal service ==> MongoDB Pod,(Setup using Secret login creds)

For a lot of this, we're writing notes in the configuration files. TBH, kind need to see some port information on the Docker site hosting the container(s)
In the MongoDB container, they've set enviornment variables for the username,(MONGO_INITDB_ROOT_USERNAME), and the password,(MONGO_INITDB_ROOTPASSWORD)

Creating base 64 encrypte passwords for mongo-secret.yaml:
ehco -n 'username'  | base64
           your username   what type of encoding

Note, creation of components matter...you can't reference secrets if they aren't created first!

Secret created: kubectl apply -f mongo-secret.yaml
Then, after secret created and we fixed our mongo config file: kubectl apply -f mongo.yaml

In YAML, you can create multiple 'documents' in one file
In yaml, this, ( --- ) is key for, "New Document)", seen in mongo.yaml
Deployments and Services usually go in one file because they usually go 
together

After creating service, see that it's working:
kubectl get service
AND validate it's connected to the pods:
kubectl describe service mongodb-service
Find all components related to Mongo with Grep:
kubectl get all | grep mongodb

Mongo express creation:
If you have two apps that are using the SAME CREDENTAILS, it might be
smart to create a config map to store that as a centralized 
credentials space for all the apps

Configmap MUST be refferenced in the cluster before refferencing it!
Create ConfigMap first:
kubectl apply -f mongo-configmap.yaml

Then Mongo-express deployment: kubectl apply -f mongo-express.yaml

To see server listening: kubectl logs mongo-express-78fcf796b8-w2vxm

To connect to the mongo-express from the web, we need an external service:

The Load balancer term is tricky...becuase it makes a Service technically external to
applicaitons...but services still load balance INTERNALLY.
Load Balancer value assigns an external IP address for applications

kubectl apply -f mongo-express.yaml
You should be able to see that Load blanacer with:
kubectl get service
When creating service, it's defaulted as 'internal' to the cluster
External has an external IP address and an IP assigned to the port
YOu should see the external IP as pending to begin with. To add it...
minikube service mongo-express-service
You can see it gave a sudo url to access this application from and
a port. Example from our test: http://192.168.49.2:30000

WIth the app open, click 'Create Database'. In practice, what happened was:
Mongo Express External Service was contacted from application ==>
That serive sent the request to the Mongo Express Pod ==>
Mongo DB Internal Service was connected to from Express Pod ==>
Finally, the MongoDB Internal Service forwarded that to the MongoDB Pod

Part 7 Kubernetes NameSpace
* Namespace - Organization for resources. A virtual Cluster inside Kubernetes
Cluster. You get 4 namespaces by default.
Kubectl get namespace. Types of Namespaces:
- kubernetes-dashboard: only with minikube
- kube-system: A system process...DON'T MODIFY!
- kube-public: Publicly accessible data. Accessable without authentification
- kube-node-lease: Contains info on 'heartbeats' of nodes. Determines
availablitly of node
- default: you create new namespace info here...if you haven't already created one

To create namespace:
kubectl create namespace NAME-OF-NameSpace
you can also use a configuartion file for a Namespace

Benefits for Namespace
- Everything is in one space, under one name.
For example, one namespace with a database, with all required resources. Then
another for monitoring, elastic-stack, and application stuff.
According to docs, you don't need to use it for a small project.
- Good for big teams, same application
- Resource sharing, for staging and development. ALso good for versioning production.
- Access and resource limits on Namespaces. So one team only has access to one namespace,
etc. You can also allocate CPU, Ram, Storage, etc for certain teams.

Organization for Namespaces

- You CAN'T access most resources from different Namespaces. For example,
Project A Namespace can't access the configmap from Project Balancer
In the actual YAMl configuration, you can access other resources from other 
Namespaces with a .NAME_SPACE annotator

- Some Components can't be created WITHIN a Namespace...like volumes or nodes.
They live globally within a cluster. To list components NOT bound to a namespace:
kubectl api-resources --namespaced=false
kubectl api-resources --namespaced=true

To create NameSpace: kubectl create namespace <namespace name>
By default, if no Namepsace is given for a component, it defaults to 'default' Namespace
Kubectl actually just substitutes the default namespace if no namespace is given.
The commands actually look like:
kubectl get configmap -n default // -n is namespace, default is default Namepsace
To create a component in a Namespace:
kubectl apply -f mysql-configmap.yaml --namespace=my-namespace
BETTER WAY: Include it in a config file

To make a namespace the default namespace:
There's a tool called kubens you need to install:
